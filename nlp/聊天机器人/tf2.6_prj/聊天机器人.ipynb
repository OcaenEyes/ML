{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf165f41-09bb-4787-8dbf-5b50e6ab38bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from configparser import SafeConfigParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b92047e-9feb-4d84-926b-b3d20a280570",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\Envs\\py3.6.5_tf2\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: The SafeConfigParser class has been renamed to ConfigParser in Python 3.2. This alias will be removed in future versions. Use ConfigParser directly instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./seq2seq.ini']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = SafeConfigParser()\n",
    "parser.read(\"./seq2seq.ini\",encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d11a019c-15ec-4f45-9d34-c25caf9d6237",
   "metadata": {},
   "outputs": [],
   "source": [
    "_conf_ints = [ (key, int(value)) for key,value in parser.items('ints')]\n",
    "_conf_floats = [ (key, float(value)) for key,value in parser.items('floats') ]\n",
    "_conf_strings = [ (key, str(value)) for key,value in parser.items('strings') ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65468e5b-6b79-42c7-8b3c-e3a1d9b33dd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vocab_inp_size': 20000,\n",
       " 'vocab_tar_size': 20000,\n",
       " 'embedding_dim': 128,\n",
       " 'train_epoch': 10,\n",
       " 'layer_size': 512,\n",
       " 'batch_size': 64,\n",
       " 'max_length': 20,\n",
       " 'number_work': 2,\n",
       " 'min_loss': 0.2,\n",
       " 'mode': 'train',\n",
       " 'train_data': 'datasets',\n",
       " 'seq_data': 'datasets/seq.data',\n",
       " 'vocab_inp_path': 'datasets/inp.vocab',\n",
       " 'vocab_tar_path': 'datasets/tar.vocab',\n",
       " 'resource_data': 'datasets/xiaohuangji50w_nofenci.conv',\n",
       " 'split_train_data': 'datasets/seq_data_',\n",
       " 'e': 'E',\n",
       " 'm': 'M',\n",
       " 'model_data': 'model_data',\n",
       " 'log_dir': 'log_dir'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(_conf_ints+_conf_floats+_conf_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03f4d0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "import jieba\n",
    "from zhon.hanzi import punctuation\n",
    "from get_config import get_config\n",
    "import io\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "85229adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e:\\GitHub\\ML\\nlp\\聊天机器人\\tf2.6_prj/seq2seq.ini\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\Envs\\py3.6.5_tf2\\lib\\site-packages\\ipykernel_launcher.py:3: DeprecationWarning: The SafeConfigParser class has been renamed to ConfigParser in Python 3.2. This alias will be removed in future versions. Use ConfigParser directly instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "conf_file = os.getcwd() + \"/seq2seq.ini\"\n",
    "print(conf_file)\n",
    "parser = SafeConfigParser()\n",
    "parser.read(conf_file,encoding=\"utf-8\")\n",
    "_conf_ints = [(key, int(value)) for key, value in parser.items('ints')]\n",
    "_conf_floats = [(key, float(value)) for key, value in parser.items('floats')]\n",
    "_conf_strings = [(key, str(value)) for key, value in parser.items('strings')]\n",
    "gConf= dict(_conf_ints+_conf_floats+_conf_strings)\n",
    "\n",
    "conv_path = gConf[\"resource_data\"]\n",
    "vocab_inp_path = gConf[\"vocab_inp_path\"]\n",
    "vocab_tar_path = gConf[\"vocab_tar_path\"]\n",
    "vocab_inp_size = gConf[\"vocab_inp_size\"]\n",
    "vocab_tar_size = gConf[\"vocab_tar_size\"]\n",
    "seq_train = gConf[\"seq_data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5fd10ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predata_util():\n",
    "    # 判断训语料文件是否存在，如果不存在则提醒\n",
    "    if not os.path.exists(conv_path):\n",
    "        print(\"找不到conv文件\")\n",
    "        exit()\n",
    "\n",
    "    # 新建一个文件，用于存放处理后的对话语料\n",
    "    seq_train_file = open(seq_train, \"w\",encoding=\"utf-8\")\n",
    "    # 打开要处理的语料，逐条读取并进行数据处理\n",
    "    with open(conv_path, encoding=\"utf-8\") as f:\n",
    "        one_conv = \"\"  # 存储一次完整的对话\n",
    "        i = 0\n",
    "        # 开始循环语料\n",
    "        for line in f:\n",
    "            line = line.strip(\"\\n\")\n",
    "            line = re.sub(r\"[%s]+\" % punctuation, \"\", line)  # 去除标点符号\n",
    "            if line == \"\":\n",
    "                continue\n",
    "            # 判断是否为一段对话的开始，如果是，则把刚处理过的语料保存下来\n",
    "            if line[0] == gConf[\"e\"]:\n",
    "                if one_conv:\n",
    "                    seq_train_file.write(one_conv[:-1] + \"\\n\")\n",
    "                    i = i + 1\n",
    "                    if i % 1000 == 0:\n",
    "                        print(\"处理进度：\", i)\n",
    "                one_conv = \"\"\n",
    "\n",
    "            # 判断是否正在处理对华语剧，如果是则进行语料的拼接处理， 以及分词\n",
    "            elif line[0] == gConf['m']:\n",
    "                one_conv = one_conv + str(\" \".join(jieba.cut(line.split(\" \")[1]))) + \"\\t\"  # 存储一次问答\n",
    "\n",
    "    # 处理完成，关闭文件\n",
    "    seq_train_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "441e65b4-2035-4994-a669-75644a175b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vocab(lang, vocab_path, vocab_size):\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=vocab_size, oov_token=3)\n",
    "    tokenizer.fit_on_texts(lang)\n",
    "    vocab = json.loads(tokenizer.to_json(ensure_ascii=False))\n",
    "    vocab[\"index_word\"] = tokenizer.index_word\n",
    "    vocab[\"word_index\"] = tokenizer.word_index\n",
    "    vocab[\"document_count\"] = tokenizer.document_count\n",
    "    vocab = json.dumps(vocab,ensure_ascii=False)\n",
    "    with open(vocab_path,'w',encoding=\"utf-8\") as f:\n",
    "        f.write(vocab)\n",
    "    f.close()\n",
    "    print(\"字典存在:{}\".format(vocab_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dc11d14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(w):\n",
    "    w = 'start'+w +'end'\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "13f6460a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "处理进度： 1000\n",
      "处理进度： 2000\n",
      "处理进度： 3000\n",
      "处理进度： 4000\n",
      "处理进度： 5000\n",
      "处理进度： 6000\n",
      "处理进度： 7000\n",
      "处理进度： 8000\n",
      "处理进度： 9000\n",
      "处理进度： 10000\n",
      "处理进度： 11000\n",
      "处理进度： 12000\n",
      "处理进度： 13000\n",
      "处理进度： 14000\n",
      "处理进度： 15000\n",
      "处理进度： 16000\n",
      "处理进度： 17000\n",
      "处理进度： 18000\n",
      "处理进度： 19000\n",
      "处理进度： 20000\n",
      "处理进度： 21000\n",
      "处理进度： 22000\n",
      "处理进度： 23000\n",
      "处理进度： 24000\n",
      "处理进度： 25000\n",
      "处理进度： 26000\n",
      "处理进度： 27000\n",
      "处理进度： 28000\n",
      "处理进度： 29000\n",
      "处理进度： 30000\n",
      "处理进度： 31000\n",
      "处理进度： 32000\n",
      "处理进度： 33000\n",
      "处理进度： 34000\n",
      "处理进度： 35000\n",
      "处理进度： 36000\n",
      "处理进度： 37000\n",
      "处理进度： 38000\n",
      "处理进度： 39000\n",
      "处理进度： 40000\n",
      "处理进度： 41000\n",
      "处理进度： 42000\n",
      "处理进度： 43000\n",
      "处理进度： 44000\n",
      "处理进度： 45000\n",
      "处理进度： 46000\n",
      "处理进度： 47000\n",
      "处理进度： 48000\n",
      "处理进度： 49000\n",
      "处理进度： 50000\n",
      "处理进度： 51000\n",
      "处理进度： 52000\n",
      "处理进度： 53000\n",
      "处理进度： 54000\n",
      "处理进度： 55000\n",
      "处理进度： 56000\n",
      "处理进度： 57000\n",
      "处理进度： 58000\n",
      "处理进度： 59000\n",
      "处理进度： 60000\n",
      "处理进度： 61000\n",
      "处理进度： 62000\n",
      "处理进度： 63000\n",
      "处理进度： 64000\n",
      "处理进度： 65000\n",
      "处理进度： 66000\n",
      "处理进度： 67000\n",
      "处理进度： 68000\n",
      "处理进度： 69000\n",
      "处理进度： 70000\n",
      "处理进度： 71000\n",
      "处理进度： 72000\n",
      "处理进度： 73000\n",
      "处理进度： 74000\n",
      "处理进度： 75000\n",
      "处理进度： 76000\n",
      "处理进度： 77000\n",
      "处理进度： 78000\n",
      "处理进度： 79000\n",
      "处理进度： 80000\n",
      "处理进度： 81000\n",
      "处理进度： 82000\n",
      "处理进度： 83000\n",
      "处理进度： 84000\n",
      "处理进度： 85000\n",
      "处理进度： 86000\n",
      "处理进度： 87000\n",
      "处理进度： 88000\n",
      "处理进度： 89000\n",
      "处理进度： 90000\n",
      "处理进度： 91000\n",
      "处理进度： 92000\n",
      "处理进度： 93000\n",
      "处理进度： 94000\n",
      "处理进度： 95000\n",
      "处理进度： 96000\n",
      "处理进度： 97000\n",
      "处理进度： 98000\n",
      "处理进度： 99000\n",
      "处理进度： 100000\n",
      "处理进度： 101000\n",
      "处理进度： 102000\n",
      "处理进度： 103000\n",
      "处理进度： 104000\n",
      "处理进度： 105000\n",
      "处理进度： 106000\n",
      "处理进度： 107000\n",
      "处理进度： 108000\n",
      "处理进度： 109000\n",
      "处理进度： 110000\n",
      "处理进度： 111000\n",
      "处理进度： 112000\n",
      "处理进度： 113000\n",
      "处理进度： 114000\n",
      "处理进度： 115000\n",
      "处理进度： 116000\n",
      "处理进度： 117000\n",
      "处理进度： 118000\n",
      "处理进度： 119000\n",
      "处理进度： 120000\n",
      "处理进度： 121000\n",
      "处理进度： 122000\n",
      "处理进度： 123000\n",
      "处理进度： 124000\n",
      "处理进度： 125000\n",
      "处理进度： 126000\n",
      "处理进度： 127000\n",
      "处理进度： 128000\n",
      "处理进度： 129000\n",
      "处理进度： 130000\n",
      "处理进度： 131000\n",
      "处理进度： 132000\n",
      "处理进度： 133000\n",
      "处理进度： 134000\n",
      "处理进度： 135000\n",
      "处理进度： 136000\n",
      "处理进度： 137000\n",
      "处理进度： 138000\n",
      "处理进度： 139000\n",
      "处理进度： 140000\n",
      "处理进度： 141000\n",
      "处理进度： 142000\n",
      "处理进度： 143000\n",
      "处理进度： 144000\n",
      "处理进度： 145000\n",
      "处理进度： 146000\n",
      "处理进度： 147000\n",
      "处理进度： 148000\n",
      "处理进度： 149000\n",
      "处理进度： 150000\n",
      "处理进度： 151000\n",
      "处理进度： 152000\n",
      "处理进度： 153000\n",
      "处理进度： 154000\n",
      "处理进度： 155000\n",
      "处理进度： 156000\n",
      "处理进度： 157000\n",
      "处理进度： 158000\n",
      "处理进度： 159000\n",
      "处理进度： 160000\n",
      "处理进度： 161000\n",
      "处理进度： 162000\n",
      "处理进度： 163000\n",
      "处理进度： 164000\n",
      "处理进度： 165000\n",
      "处理进度： 166000\n",
      "处理进度： 167000\n",
      "处理进度： 168000\n",
      "处理进度： 169000\n",
      "处理进度： 170000\n",
      "处理进度： 171000\n",
      "处理进度： 172000\n",
      "处理进度： 173000\n",
      "处理进度： 174000\n",
      "处理进度： 175000\n",
      "处理进度： 176000\n",
      "处理进度： 177000\n",
      "处理进度： 178000\n",
      "处理进度： 179000\n",
      "处理进度： 180000\n",
      "处理进度： 181000\n",
      "处理进度： 182000\n",
      "处理进度： 183000\n",
      "处理进度： 184000\n",
      "处理进度： 185000\n",
      "处理进度： 186000\n",
      "处理进度： 187000\n",
      "处理进度： 188000\n",
      "处理进度： 189000\n",
      "处理进度： 190000\n",
      "处理进度： 191000\n",
      "处理进度： 192000\n",
      "处理进度： 193000\n",
      "处理进度： 194000\n",
      "处理进度： 195000\n",
      "处理进度： 196000\n",
      "处理进度： 197000\n",
      "处理进度： 198000\n",
      "处理进度： 199000\n",
      "处理进度： 200000\n",
      "处理进度： 201000\n",
      "处理进度： 202000\n",
      "处理进度： 203000\n",
      "处理进度： 204000\n",
      "处理进度： 205000\n",
      "处理进度： 206000\n",
      "处理进度： 207000\n",
      "处理进度： 208000\n",
      "处理进度： 209000\n",
      "处理进度： 210000\n",
      "处理进度： 211000\n",
      "处理进度： 212000\n",
      "处理进度： 213000\n",
      "处理进度： 214000\n",
      "处理进度： 215000\n",
      "处理进度： 216000\n",
      "处理进度： 217000\n",
      "处理进度： 218000\n",
      "处理进度： 219000\n",
      "处理进度： 220000\n",
      "处理进度： 221000\n",
      "处理进度： 222000\n",
      "处理进度： 223000\n",
      "处理进度： 224000\n",
      "处理进度： 225000\n",
      "处理进度： 226000\n",
      "处理进度： 227000\n",
      "处理进度： 228000\n",
      "处理进度： 229000\n",
      "处理进度： 230000\n",
      "处理进度： 231000\n",
      "处理进度： 232000\n",
      "处理进度： 233000\n",
      "处理进度： 234000\n",
      "处理进度： 235000\n",
      "处理进度： 236000\n",
      "处理进度： 237000\n",
      "处理进度： 238000\n",
      "处理进度： 239000\n",
      "处理进度： 240000\n",
      "处理进度： 241000\n",
      "处理进度： 242000\n",
      "处理进度： 243000\n",
      "处理进度： 244000\n",
      "处理进度： 245000\n",
      "处理进度： 246000\n",
      "处理进度： 247000\n",
      "处理进度： 248000\n",
      "处理进度： 249000\n",
      "处理进度： 250000\n",
      "处理进度： 251000\n",
      "处理进度： 252000\n",
      "处理进度： 253000\n",
      "处理进度： 254000\n",
      "处理进度： 255000\n",
      "处理进度： 256000\n",
      "处理进度： 257000\n",
      "处理进度： 258000\n",
      "处理进度： 259000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-e1039cacb852>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpredata_util\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseq_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mword_pairs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpreprocess_sentence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\t\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0minput_lang\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget_lang\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mword_pairs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-27-83e9471c9c29>\u001b[0m in \u001b[0;36mpredata_util\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mgConf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"e\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mone_conv\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m                     \u001b[0mseq_train_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mone_conv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m                     \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m1000\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "predata_util()\n",
    "\n",
    "lines = io.open(seq_train,encoding=\"utf-8\").readlines()\n",
    "word_pairs = [[preprocess_sentence(w) for w in l.split(\"\\t\")] for l in lines]\n",
    "input_lang,target_lang = zip(*word_pairs)\n",
    "\n",
    "create_vocab(input_lang,vocab_inp_path,vocab_inp_size)\n",
    "create_vocab(target_lang,vocab_tar_path,vocab_tar_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20012fc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.6_tf2.6",
   "language": "python",
   "name": "py3.6_tf2.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
