{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3b9a91f-5281-4326-a0f4-9a886126c892",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "import json\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d198569-9a9a-4954-8831-33e960f4458e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_config import get_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8395e2f9-bbee-44a6-adf7-d70b2099ae06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\GitHub\\ML\\nlp\\聊天机器人\\tf2.6_prj/seq2seq.ini\n"
     ]
    }
   ],
   "source": [
    "# 初始化超参字典\n",
    "gConf = {}\n",
    "gConf = get_config()\n",
    "\n",
    "# 通过超参字典为vocab_in_size,vocab_tar_size,embedding_dim,units等赋值\n",
    "vocab_inp_size = gConf[\"vocab_inp_size\"]\n",
    "vocab_tar_size = gConf[\"vocab_tar_size\"]\n",
    "embedding_dim = gConf[\"embedding_dim\"]\n",
    "vocab_inp_path = gConf[\"vocab_inp_path\"]\n",
    "vocab_tar_path = gConf[\"vocab_tar_path\"]\n",
    "units = gConf[\"layer_size\"]\n",
    "BATCH_SIZE = gConf[\"batch_size\"]\n",
    "\n",
    "max_length_inp = gConf[\"max_length\"]\n",
    "max_length_tar = gConf[\"max_length\"]\n",
    "model_path = gConf[\"model_data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8154cdc-3202-45a2-9399-a5e32bb13fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_inputs = keras.Input(shape=(20),batch_size=BATCH_SIZE,dtype=tf.int32,name=\"encode_inps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88f44280-7408-4659-9bb9-79b1b0cbfc68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(64, 20) dtype=int32 (created by layer 'encode_inps')>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e52fb34-8e85-4600-8b0d-57e45e018b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_inputs = keras.Input(shape=(1),batch_size=BATCH_SIZE,dtype=tf.int32,name=\"decode_inps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d63d1f8-bbed-40e3-985c-de542c2af89f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(64, 1) dtype=int32 (created by layer 'decode_inps')>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d7a17c3-400b-493c-9bc6-a1be93121b53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.embeddings.Embedding at 0x28ee11196a0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_embed =keras.layers.Embedding(input_dim= vocab_inp_size,output_dim = embedding_dim, name=\"encode_embed\")\n",
    "encode_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1967761-21ae-4432-b994-5ff1e5b47ceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(64, 20, 128) dtype=float32 (created by layer 'encode_embed')>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_inputs_embed = encode_embed(encode_inputs)\n",
    "encode_inputs_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fef347db-8a99-42a7-82a6-16e658a098d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.recurrent_v2.GRU at 0x28ee09cf518>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_gru=keras.layers.GRU(units,return_sequences=True, return_state=True,name=\"encode_gru\",recurrent_initializer=\"glorot_uniform\")\n",
    "encode_gru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "efd3ce44-5e04-40ad-8e4d-889a8d9608f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(64, 20, 256), dtype=tf.float32, name=None), name='encode_gru/PartitionedCall:1', description=\"created by layer 'encode_gru'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(64, 256), dtype=tf.float32, name=None), name='encode_gru/PartitionedCall:2', description=\"created by layer 'encode_gru'\")\n"
     ]
    }
   ],
   "source": [
    "encode_outs, encode_state = encode_gru(encode_inputs_embed)\n",
    "print(encode_outs)\n",
    "print(encode_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3c3f34ce-6618-4d2d-971d-e1cf8b236e84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.embeddings.Embedding at 0x28eef92a7f0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_embed =keras.layers.Embedding(input_dim= vocab_tar_size,output_dim = embedding_dim, name=\"decode_embed\")\n",
    "decode_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eb36760f-5008-450f-b4ea-e8dfe9fd0cfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(64, 1, 128) dtype=float32 (created by layer 'decode_embed')>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_inputs_embed = decode_embed(decode_inputs)\n",
    "decode_inputs_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "101d2b2e-e75a-4790-9c42-ba4f5fa1e557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.recurrent_v2.GRU at 0x28eef8f2978>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_gru=keras.layers.GRU(units,return_sequences=True, return_state=True,name=\"decode_gru\",recurrent_initializer=\"glorot_uniform\")\n",
    "decode_gru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f77f85db-f22e-4944-b4d3-ef32dd25d03f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(64, 1, 256), dtype=tf.float32, name=None), name='decode_gru/PartitionedCall:1', description=\"created by layer 'decode_gru'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(64, 256), dtype=tf.float32, name=None), name='decode_gru/PartitionedCall:2', description=\"created by layer 'decode_gru'\")\n"
     ]
    }
   ],
   "source": [
    "decode_outs, decode_state  = decode_gru(decode_inputs_embed,initial_state=encode_state)\n",
    "print(decode_outs)\n",
    "print(decode_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e9f95a5b-3530-4825-8a5f-cf94403e96de",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.Model):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        # 注意力网络的初始化\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    \"\"\"\n",
    "    传入值：\n",
    "        features：编码器的输出，(64, 16, 1024) 即 (BATCH_SIZE, 输入序列最大长度句子的长度, 隐藏层中的隐藏神经元数量)\n",
    "        hidden：解码器的隐层输出状态，(64, 1024) 即 (batch_size, hidden_size) (BATCH_SIZE, 隐藏层中的隐藏神经元数量)\n",
    "    返回值：\n",
    "        attention_result：(64, 1024) 即 (batch size, units) (BATCH_SIZE, 隐藏层中的隐藏神经元数量)\n",
    "        attention_weights：(64, 16, 1) 即 (batch_size, sequence_length, 1) (BATCH_SIZE, 输入序列最大长度句子的长度, 1)\n",
    "    \"\"\"\n",
    "\n",
    "    def call(self, features, hidden):\n",
    "        \"\"\"\n",
    "        description: 具体计算函数\n",
    "        :param features: 编码器的输出\n",
    "        :param hidden: 解码器的隐层输出状态\n",
    "        return: 通过注意力机制处理后的结果和注意力权重attention_weights\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        1.hidden_with_time_axis = tf.expand_dims(hidden, 1)\n",
    "                解码器的隐层输出状态hidden，(64, 1024) 即 (batch_size, hidden_size) (BATCH_SIZE, 隐藏层中的隐藏神经元数量)。\n",
    "                hidden扩展一个维度从(64, 1024)变成(64, 1,1024)。\n",
    "        2.score = tf.nn.tanh(self.W1(features) + self.W2(hidden_with_time_axis))\n",
    "                计算注意力得分score。\n",
    "                features：编码器的输出，(64, 16, 1024)。\n",
    "                hidden_with_time_axis：解码器的隐层输出状态，(64, 1,1024)\n",
    "                W1和W2：Dense(隐藏层中的隐藏神经元数量1024)\n",
    "                tanh(W1(features) + W2(hidden_with_time_axis))：\n",
    "                ---> tanh(W1((64, 16, 1024)) + W2((64, 1,1024)))\n",
    "                ---> tanh((64, 16, 1024))\n",
    "                ---> (64, 16, 1024) 即 (BATCH_SIZE, 输入序列最大长度句子的长度, 隐藏层中的隐藏神经元数量)\n",
    "        3.attention_weights = tf.nn.softmax(self.V(score), axis=1)\n",
    "                计算注意力权重attention_weights。\n",
    "                V：Dense(隐藏层中的隐藏神经元数量1)\n",
    "                softmax(V(score), axis=1)\n",
    "                ---> softmax(V((64, 16, 1024)), axis=1)\n",
    "                ---> softmax((64, 16, 1), axis=1)\n",
    "                ---> (64, 16, 1) 即 (BATCH_SIZE, 输入序列最大长度句子的长度, 1)\n",
    "                因为注意力得分score的形状是(BATCH_SIZE, 输入序列最大长度句子的长度, 隐藏层中的隐藏神经元数量)，\n",
    "                输入序列最大长度句子的长度(max_length)是输入的长度。\n",
    "                因为我们想为每个输入长度分配一个权重，所以softmax应该用在第一个轴(max_length)上axis=1，\n",
    "                而softmax默认被应用于最后一个轴axis=-1。\n",
    "        4.context_vector = tf.reduce_sum(attention_weights * features, axis=1)\n",
    "                获得注意力机制处理后的结果context_vector。\n",
    "                reduce_sum(attention_weights * features, axis=1)\n",
    "                ---> reduce_sum((64, 16, 1) * (64, 16, 1024), axis=1)\n",
    "                ---> reduce_sum((64, 16, 1024), axis=1)\n",
    "                ---> (64, 1024) 即 (BATCH_SIZE, 隐藏层中的隐藏神经元数量)\n",
    "        \"\"\"\n",
    "        # 将hidden增加一个维度,(batch_size, hidden_size) --> (batch_size, 1, hidden_size)\n",
    "        hidden_with_time_axis = tf.expand_dims(hidden, 1)\n",
    "        # 根据公式计算注意力得分, 输出score的形状为: (batch_size, 16, hidden_size)\n",
    "        score = tf.nn.tanh(self.W1(features) + self.W2(hidden_with_time_axis))\n",
    "        # 根据公式计算注意力权重, 输出attention_weights形状为: (batch_size, 16, 1)\n",
    "        attention_weights = tf.nn.softmax(self.V(score), axis=1)\n",
    "        # 最后根据公式获得注意力机制处理后的结果context_vector\n",
    "        # context_vector的形状为: (batch_size, hidden_size)\n",
    "        context_vector = attention_weights * features\n",
    "        # 将乘机后的context_vector按行相加，进行压缩得到最终的context_vector\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8cf0b5a8-1947-40a9-a1eb-4185234fd21a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.BahdanauAttention at 0x28f03865f98>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atten_layer = BahdanauAttention(units)\n",
    "atten_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d3f369bf-22c7-48cf-9d84-304dbf8050d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(64, 256), dtype=tf.float32, name=None), name='bahdanau_attention/Sum:0', description=\"created by layer 'bahdanau_attention'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(64, 20, 1), dtype=tf.float32, name=None), name='bahdanau_attention/transpose_1:0', description=\"created by layer 'bahdanau_attention'\")\n"
     ]
    }
   ],
   "source": [
    "context_vector, attention_weights = atten_layer(encode_outs,decode_state)\n",
    "print(context_vector)\n",
    "print(attention_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "85ed5cc9-c41e-4efd-80da-d9e19638fd3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(64, 1, 384) dtype=float32 (created by layer 'concat_layer')>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.layers.Concatenate(axis=-1, name='concat_layer')([tf.expand_dims(context_vector, 1), decode_inputs_embed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd192a08-84ca-4b05-9f7d-40b95ccf636b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.6.5_tf2",
   "language": "python",
   "name": "py3.6.5_tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
